---
title: "Testing multilingual setup"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
bibliography: references.bib
---

The code used by Wolf and colleagues to obtain their results and published on Github mixes three different coding languages: python, R and Julia. Moreover, although the code is generally clearly written and includes some explanatory comments, several adjustments in the code are required to enable it to run on a different machine. This document provides a technical procedure to enable the reproducibility of the computations shared by Wolf and colleagues.

## Comments on the reproducibility of the analyses.

Some good practices are not respected. The analysis mentions that the sources are publicly available, but the data is not available as is: needs an access to Google Earth Engine. The API is not public and this accessibility is conditionned by the will of Google to keep its platform in free access and not to make any evolution in the GEE API that would not be backward compatible. For these resons, it seems recommended to archive the data outputed by sources which reproducibility is not guaranteed.

It is also very likely that some data used for the analysis gets updated: UICN species data is regularly updated WDPA data on protected area also

The obtaining of the data is not documented for BOTW and IUCN range maps.

## Technical environment

It is possible to combine different programming languages in statistical computing environments such as Jupyter or RMarkdown, or its new generation Quarto. We decided to use Quarto because of its versatility and our familiarity of this tool.

Quarto can be obtained at www.quarto.org.

Requires Linux or a Windows machine running WSL, otherwise a strong rewriting of some files is needed. We run it on a Windows personal computer.

## Prerequisites

### Google services

Have a gmail account to access google services Google Earth Engine and Google Drive.

### wget

The code requires a working installation of Wget. Wget comes with linux platform and can be installed on MAC. On Windows, it requires Windows Subsystem for Linux.

## Set up R

We install all R dependencies that might be required

```{r}

# Install from Github --------------------------------------------------------

# Some packages need to be installed from developper sources because there are
# not available or official sources have some issues.
# Installing version 1.3.5 which is the last working version apparently
remotes::install_github("https://github.com/cran/doMC/tree/fbea362b96cc4469deb6065ff9fbd5d4794ccac1")
remotes::install_github("https://github.com/cran/gdalUtils")
remotes::install_github("jonocarroll/ggeasy")

# Install from CRAN ------------------------------------------------------------

# These packages are available from the usual source from R
required_packages <- c( # List all required R packages
  "reticulate", # To interact with python (normally installed with Quarto)
  "JuliaCall", # To interact with Julia 
  "tidyverse", # To facilitate data manipulation
  # All packages below are used in Wolf and al. code files:
  "countrycode",
  "cowplot",
  "data.table",
  "dtplyr",
  "fasterize",
  "foreach",
  "foreign",
  "ggforce",
  "ggplot2",
  "ggrepel",
  "GpGp",
  "grid",
  "jsonlite",
  "landscapetools",
  "lme4",
  "MCMC.OTU",
  "ncdf4",
  "parallel",
  "pbapply",
  "plyr",
  "raster",
  "rasterVis",
  "rbounds",
  "RColorBrewer",
  "RCurl",
  "readr",
  "reshape2",
  "rgdal",
  "rjson",
  "rnaturalearth",
  "scales",
  "sf",
  "smoothr",
  "spaMM",
  "spgwr",
  "spmoran",
  "spNNGP",
  "stars",
  "stringr",
  "tidyverse",
  "unix",
  "velox",
  "viridis",
  "wbstats") 
missing <- !(required_packages %in% installed.packages())

# Install 
if(any(missing)) install.packages(required_packages[missing])
```

## Set up python

```{r}
library(reticulate) # to run python from R

# Variables to modify
my_envname <- "replication-wolf"
scripts_to_run <- "003" # or c("001", "003") or "001"

# Install python if not already present
if (!dir.exists(miniconda_path())) {
  install_miniconda()
}
# Create environment if not already
if (!my_envname %in% conda_list()$name) {
  conda_create(my_envname)
}
# Packages needed for each script
requirements <- list(
  "001" = c("earthengine-api", "rasterio", "pandas", "pydrive"),
  "003" = c("fiona", "rasterio", "ray-default", "dbfread", "pandas"))
# Combined depending on the variable defined at beginning of code chunk
required <- unique(unlist(requirements[scripts_to_run]))
# identify which ones are missing
missing_packages <- required[!required %in% py_list_packages(my_envname)$package]
# Install those
conda_install(envname = my_envname, 
              packages = missing_packages)
# Activate the corresponding environment
use_condaenv(my_envname)
```

Create an authorization

```{python}
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive

gauth = GoogleAuth()
# Try to load saved client credentials
gauth.LoadCredentialsFile("mycreds.txt")
if gauth.credentials is None:
    # Authenticate if they're not there
    gauth.LocalWebserverAuth()
elif gauth.access_token_expired:
    # Refresh them if expired
    gauth.Refresh()
else:
    # Initialize the saved creds
    gauth.Authorize()
# Save the current credentials to a file
gauth.SaveCredentialsFile("mycreds.txt")
```

## Set up Julia

First we install or set-up Julia from R if needed.

```{r}
library(JuliaCall)
# Install or set up julia if needed
julia_setup()
```

We also install the packages used in the code of Wolf et al.

```{julia}
using Pkg
Pkg.add("ArchGDAL")
Pkg.add("DataFrames")
Pkg.add("Discretizers")
Pkg.add("Shapefile")
Pkg.add("FreqTables")
Pkg.add("Plots")
Pkg.add("StatsBase")
Pkg.add("CSV")
Pkg.add("LibGEOS")
```

## Harmonize paths

### Make code paths generic

```{r}
library(tidyverse)

replace_all <- function(x, pattern, replacement) {
  print(x)
  readLines(x) %>%
    str_replace_all(pattern, replacement) %>%
    writeLines(x)
}

list.files(pattern = "[0-9]{3}.*") %>%
  map(replace_all, "/home/chrisgraywolf/analysis_desktop/", "")
```

### Add required subfolders

```{r}
dir.create("data_input")
dir.create("temp")
```

## Adapt to Windows system (optionnal)

Install `parallel`: On Windows, run the command `wsl sudo apt-get update` followed by the command `wsl sudo apt-get install parallel`. On Linux, run the same commands without `wsl`, that is run the command `sudo apt-get update` followed by the command `sudo apt-get install parallel`.

```{r}
# Replace all wget calls by wsl wget
replace_all("002 - dl_IUCN.R", "wget", "wsl wget")

```

## Testing R

```{r}
1 + 1

```

## Testing python

Needs reticulate (already installed here).

```{python}
1 + 1
```

## Testing Julia

## Prepare data

The data from IUCN now comes in 2 parts for the reptiles.

```{r}
library(tidyverse)
library(sf)

reptiles1 <- st_read("data_input/range_maps/REPTILES_PART1.shp") 
  
reptiles1 %>%
  select(-OBJECTID) %>%
  st_write(dsn = "data_input/range_maps/REPTILES_PART2.shp", append = TRUE)

file.rename(list.files(path = "data_input/range_maps", pattern ="REPTILES_PART2",
                       full.names = TRUE),
            str_replace(list.files(path = "data_input/range_maps",
                                   pattern="REPTILES_PART2", full.names = TRUE), 
                        pattern="REPTILES_PART2", "REPTILES"))
```

## 
